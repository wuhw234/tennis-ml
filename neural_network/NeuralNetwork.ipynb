{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    'p1_height',\n",
    "    'p2_height',\n",
    "    'p1_age',\n",
    "    'p2_age',\n",
    "    'p1_rating',\n",
    "    'p2_rating',\n",
    "    'p1_dev',\n",
    "    'p2_dev',\n",
    "    'p1_surface_rating',\n",
    "    'p2_surface_rating',\n",
    "    'p1_surface_dev',\n",
    "    'p2_surface_dev',\n",
    "    'p1_w',\n",
    "    'p2_w',\n",
    "    'p1_l',\n",
    "    'p2_l',\n",
    "    'p1_surface_w',\n",
    "    'p2_surface_w',\n",
    "    'p1_surface_l',\n",
    "    'p2_surface_l',\n",
    "    'p1_inactive_days',\n",
    "    'p2_inactive_days',\n",
    "    'p1_recent_rating',\n",
    "    'p2_recent_rating'\n",
    "]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'is_hard',\n",
    "    'is_clay',\n",
    "    'is_grass',\n",
    "    'is_bo5',\n",
    "    'p1_lefty',\n",
    "    'p2_lefty',\n",
    "    'p1_home',\n",
    "    'p2_home'\n",
    "    \n",
    "]\n",
    "\n",
    "dataframe = pd.read_csv('../data/matches.csv')[:76425]\n",
    "validation = pd.read_csv('../data/matches.csv')[76425:]\n",
    "\n",
    "\n",
    "# def build_model(preprocessing_head, inputs, hp):\n",
    "#   body = tf.keras.Sequential([\n",
    "#     keras.layers.InputLayer(input_shape=(32,)),\n",
    "#     keras.layers.Dense(hp.Int('hidden_size', 30, 300, step=30), activation='relu'),\n",
    "#     keras.layers.Dropout(hp.Float('dropout', 0, 0.5, step=0.1)),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "#   ])\n",
    "\n",
    "#   preprocessed_inputs = preprocessing_head(inputs)\n",
    "#   result = body(preprocessed_inputs)\n",
    "#   model = tf.keras.Model(inputs, result)\n",
    "\n",
    "#   model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "#                 optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 0.0001, 0.01, sampling='log')))\n",
    "#   return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, preprocessing_head, inputs):\n",
    "        self.preprocessing_head = preprocessing_head\n",
    "        self.inputs = inputs\n",
    "    def build(self, hp):\n",
    "        body = tf.keras.Sequential([\n",
    "            keras.layers.InputLayer(input_shape=(32,)),\n",
    "            keras.layers.Dense(hp.Int('hidden_size', 20, 500, step=20), activation='relu'),\n",
    "            keras.layers.Dropout(hp.Float('dropout', 0, 0.5, step=0.05)),\n",
    "            keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        preprocessed_inputs = self.preprocessing_head(self.inputs)\n",
    "        result = body(preprocessed_inputs)\n",
    "        model = tf.keras.Model(self.inputs, result)\n",
    "\n",
    "        model.compile(\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                      optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 0.0001, 0.01, sampling='log'))\n",
    "                      )\n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Int(\"batch_size\", 50, 10050, step=500),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dataframe):\n",
    "    labels = dataframe.pop('p1_win')\n",
    "    dataframe.pop('match_hash')\n",
    "    dataframe.pop('tourney_name')\n",
    "    dataframe.pop('tourney_date')\n",
    "    dataframe.pop('p1_name')\n",
    "    dataframe.pop('p2_name')\n",
    "\n",
    "    dataframe_features = dataframe.copy()\n",
    "\n",
    "    inputs = {}\n",
    "\n",
    "    # match column names with input objects\n",
    "    for name, column in dataframe_features.items():\n",
    "        dtype = tf.float32\n",
    "        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "    numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                    if name in NUMERIC_FEATURES}\n",
    "\n",
    "    # normalize the numeric inputs and gather them in an array\n",
    "    x = keras.layers.Concatenate()(list(numeric_inputs.values()))\n",
    "    norm = keras.layers.Normalization()\n",
    "    norm.adapt(np.array(dataframe[numeric_inputs.keys()]))\n",
    "    all_numeric_inputs = norm(x)\n",
    "\n",
    "    preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "    for name, input in inputs.items():\n",
    "        if name in NUMERIC_FEATURES:\n",
    "            continue\n",
    "        preprocessed_inputs.append(input)\n",
    "\n",
    "    preprocessed_inputs_cat = keras.layers.Concatenate()(preprocessed_inputs)\n",
    "    preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "    features_dict = {name: np.array(value) for name, value in dataframe_features.items()}\n",
    "    f_dict = {name:values for name, values in features_dict.items()}\n",
    "    preprocessing(f_dict)\n",
    "\n",
    "    data_model = MyHyperModel(preprocessing, inputs)\n",
    "\n",
    "    return data_model, features_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuning\\untitled_project\\tuner0.json\n",
      "\n",
      "Search: Running Trial #11\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "380               |420               |hidden_size\n",
      "0.15              |0                 |dropout\n",
      "0.00029284        |0.0034253         |learning_rate\n",
      "50                |1050              |batch_size\n",
      "\n",
      "Epoch 1/100\n",
      "1529/1529 [==============================] - 8s 5ms/step - loss: 0.6231 - val_loss: 0.5710\n",
      "Epoch 2/100\n",
      "1529/1529 [==============================] - 7s 5ms/step - loss: 0.6157 - val_loss: 0.5614\n",
      "Epoch 3/100\n",
      "1529/1529 [==============================] - 8s 5ms/step - loss: 0.6134 - val_loss: 0.5522\n",
      "Epoch 4/100\n",
      " 894/1529 [================>.............] - ETA: 2s - loss: 0.6106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m _, val_features_dict, val_labels \u001b[39m=\u001b[39m get_model(validation)\n\u001b[0;32m      7\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mBayesianOptimization(data_model, objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtuning\u001b[39m\u001b[39m'\u001b[39m, max_trials\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(x\u001b[39m=\u001b[39;49mfeatures_dict, y\u001b[39m=\u001b[39;49mlabels, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      9\u001b[0m              validation_data\u001b[39m=\u001b[39;49m(val_features_dict, val_labels),\n\u001b[0;32m     10\u001b[0m              callbacks\u001b[39m=\u001b[39;49m[tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)]\n\u001b[0;32m     11\u001b[0m             )\n\u001b[0;32m     12\u001b[0m \u001b[39m# num_rows = dataframe.shape[0]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# training_end_index = math.floor((2/3) * num_rows)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# # train_dataframe = dataframe.iloc[:training_end_index]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# # val_dataframe = dataframe.iloc[training_end_index:]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# train_dataframe = dataframe.iloc[:300]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# val_dataframe = dataframe.iloc[300:450]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:210\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    211\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    212\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:250\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    249\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    251\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    252\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:215\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 215\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    217\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[0;32m    219\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    220\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    221\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    223\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    231\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:286\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    285\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 286\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    288\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    289\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:213\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    212\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 213\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    215\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m )\n\u001b[0;32m    217\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "Cell \u001b[1;32mIn[24], line 24\u001b[0m, in \u001b[0;36mMyHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     25\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[0;32m     26\u001b[0m         batch_size\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39mInt(\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m10050\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m),\n\u001b[0;32m     27\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     28\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_model, features_dict, labels = get_model(dataframe)\n",
    "# data_model.fit(x=features_dict, y=labels, epochs=50)\n",
    "# data_model.save('test')\n",
    "\n",
    "_, val_features_dict, val_labels = get_model(validation)\n",
    "\n",
    "tuner = kt.BayesianOptimization(data_model, objective='val_loss', directory='tuning', max_trials=100)\n",
    "tuner.search(x=features_dict, y=labels, epochs=100, \n",
    "             validation_data=(val_features_dict, val_labels),\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=4)]\n",
    "            )\n",
    "# num_rows = dataframe.shape[0]\n",
    "# training_end_index = math.floor((2/3) * num_rows)\n",
    "# # train_dataframe = dataframe.iloc[:training_end_index]\n",
    "# # val_dataframe = dataframe.iloc[training_end_index:]\n",
    "# train_dataframe = dataframe.iloc[:300]\n",
    "# val_dataframe = dataframe.iloc[300:450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "best {'hidden_size': 420, 'dropout': 0.0, 'learning_rate': 0.003425317024450299, 'batch_size': 1050}\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "print('best', best_hp.values)\n",
    "\n",
    "\n",
    "# reloaded = tf.keras.models.load_model('test')\n",
    "# validation = pd.read_csv('../data/matches.csv')[76425:80000]\n",
    "# _, features_dict, labels = get_model(validation)\n",
    "# results = reloaded.evaluate(features_dict, labels)\n",
    "# print(results)\n",
    "# predictions = reloaded.predict(features_dict)\n",
    "# for i in range(76425, 76525):\n",
    "#     pred_index = i - 76425\n",
    "#     print('Prediction:', predictions[pred_index], 'Result:', labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c387c56ae450897d1d6677bb1bb04b8f7b3f7f9924967827e96c8d61cb0c0e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
