{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    'p1_height',\n",
    "    'p2_height',\n",
    "    'p1_age',\n",
    "    'p2_age',\n",
    "    'p1_rating',\n",
    "    'p2_rating',\n",
    "    'p1_dev',\n",
    "    'p2_dev',\n",
    "    'p1_surface_rating',\n",
    "    'p2_surface_rating',\n",
    "    'p1_surface_dev',\n",
    "    'p2_surface_dev',\n",
    "    'p1_w',\n",
    "    'p2_w',\n",
    "    'p1_l',\n",
    "    'p2_l',\n",
    "    'p1_surface_w',\n",
    "    'p2_surface_w',\n",
    "    'p1_surface_l',\n",
    "    'p2_surface_l',\n",
    "    'p1_inactive_days',\n",
    "    'p2_inactive_days',\n",
    "    'p1_recent_rating',\n",
    "    'p2_recent_rating'\n",
    "]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'is_hard',\n",
    "    'is_clay',\n",
    "    'is_grass',\n",
    "    'is_bo5',\n",
    "    'p1_lefty',\n",
    "    'p2_lefty',\n",
    "    'p1_home',\n",
    "    'p2_home'\n",
    "    \n",
    "]\n",
    "\n",
    "dataframe = pd.read_csv('../data/matches.csv')[7389:76425]\n",
    "validation = pd.read_csv('../data/matches.csv')[76425:]\n",
    "\n",
    "\n",
    "def build_model(preprocessing_head, inputs, hidden_layer, learning_rate, dropout):\n",
    "  body = tf.keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(32,)),\n",
    "    keras.layers.Dense(hidden_layer, activation='relu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                metrics='acc')\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, preprocessing_head, inputs):\n",
    "        self.preprocessing_head = preprocessing_head\n",
    "        self.inputs = inputs\n",
    "    def build(self, hp):\n",
    "        body = tf.keras.Sequential([\n",
    "            keras.layers.InputLayer(input_shape=(32,)),\n",
    "            keras.layers.Dense(hp.Int('hidden_size', 200, 600), activation='relu'),\n",
    "            keras.layers.Dropout(hp.Float('dropout', 0.05, 0.5)),\n",
    "            keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        preprocessed_inputs = self.preprocessing_head(self.inputs)\n",
    "        result = body(preprocessed_inputs)\n",
    "        model = tf.keras.Model(self.inputs, result)\n",
    "\n",
    "        model.compile(\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                      optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 0.003, 0.03)),\n",
    "                      metrics=['acc']\n",
    "                      )\n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Int(\"batch_size\", 2000, 6000),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dataframe, hidden_layer, learning_rate, dropout):\n",
    "    labels = dataframe.pop('p1_win')\n",
    "    dataframe.pop('match_hash')\n",
    "    dataframe.pop('tourney_name')\n",
    "    dataframe.pop('tourney_date')\n",
    "    dataframe.pop('p1_name')\n",
    "    dataframe.pop('p2_name')\n",
    "\n",
    "    dataframe_features = dataframe.copy()\n",
    "\n",
    "    inputs = {}\n",
    "\n",
    "    # match column names with input objects\n",
    "    for name, column in dataframe_features.items():\n",
    "        dtype = tf.float32\n",
    "        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "    numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                    if name in NUMERIC_FEATURES}\n",
    "\n",
    "    # normalize the numeric inputs and gather them in an array\n",
    "    x = keras.layers.Concatenate()(list(numeric_inputs.values()))\n",
    "    norm = keras.layers.Normalization()\n",
    "    norm.adapt(np.array(dataframe[numeric_inputs.keys()]))\n",
    "    all_numeric_inputs = norm(x)\n",
    "\n",
    "    preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "    for name, input in inputs.items():\n",
    "        if name in NUMERIC_FEATURES:\n",
    "            continue\n",
    "        preprocessed_inputs.append(input)\n",
    "\n",
    "    preprocessed_inputs_cat = keras.layers.Concatenate()(preprocessed_inputs)\n",
    "    preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "    features_dict = {name: np.array(value) for name, value in dataframe_features.items()}\n",
    "    f_dict = {name:values for name, values in features_dict.items()}\n",
    "    preprocessing(f_dict)\n",
    "\n",
    "    # data_model = MyHyperModel(preprocessing, inputs)\n",
    "    data_model = build_model(preprocessing, inputs, hidden_layer, learning_rate, dropout)\n",
    "\n",
    "    return data_model, features_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000\n",
      "12/12 [==============================] - 3s 194ms/step - loss: 0.6668 - acc: 0.6228 - val_loss: 0.6203 - val_acc: 0.6464\n",
      "Epoch 2/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.6199 - acc: 0.6548 - val_loss: 0.5819 - val_acc: 0.6946\n",
      "Epoch 3/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.6140 - acc: 0.6592 - val_loss: 0.5693 - val_acc: 0.7020\n",
      "Epoch 4/20000\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.6113 - acc: 0.6613 - val_loss: 0.5638 - val_acc: 0.7133\n",
      "Epoch 5/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.6096 - acc: 0.6635 - val_loss: 0.5469 - val_acc: 0.7303\n",
      "Epoch 6/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.6086 - acc: 0.6646 - val_loss: 0.5426 - val_acc: 0.7346\n",
      "Epoch 7/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.6070 - acc: 0.6649 - val_loss: 0.5348 - val_acc: 0.7388\n",
      "Epoch 8/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.6054 - acc: 0.6673 - val_loss: 0.5328 - val_acc: 0.7451\n",
      "Epoch 9/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.6048 - acc: 0.6685 - val_loss: 0.5247 - val_acc: 0.7521\n",
      "Epoch 10/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.6051 - acc: 0.6684 - val_loss: 0.5217 - val_acc: 0.7616\n",
      "Epoch 11/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.6041 - acc: 0.6695 - val_loss: 0.5213 - val_acc: 0.7498\n",
      "Epoch 12/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.6039 - acc: 0.6697 - val_loss: 0.5200 - val_acc: 0.7558\n",
      "Epoch 13/20000\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.6027 - acc: 0.6700 - val_loss: 0.5182 - val_acc: 0.7555\n",
      "Epoch 14/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.6026 - acc: 0.6696 - val_loss: 0.5126 - val_acc: 0.7561\n",
      "Epoch 15/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.6011 - acc: 0.6725 - val_loss: 0.5002 - val_acc: 0.7740\n",
      "Epoch 16/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5994 - acc: 0.6735 - val_loss: 0.4967 - val_acc: 0.7700\n",
      "Epoch 17/20000\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.5998 - acc: 0.6733 - val_loss: 0.5099 - val_acc: 0.7588\n",
      "Epoch 18/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5999 - acc: 0.6728 - val_loss: 0.4980 - val_acc: 0.7718\n",
      "Epoch 19/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5996 - acc: 0.6741 - val_loss: 0.4924 - val_acc: 0.7769\n",
      "Epoch 20/20000\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 0.5973 - acc: 0.6754 - val_loss: 0.4839 - val_acc: 0.7786\n",
      "Epoch 21/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5964 - acc: 0.6753 - val_loss: 0.4887 - val_acc: 0.7740\n",
      "Epoch 22/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5965 - acc: 0.6759 - val_loss: 0.4913 - val_acc: 0.7723\n",
      "Epoch 23/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5973 - acc: 0.6752 - val_loss: 0.4951 - val_acc: 0.7689\n",
      "Epoch 24/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5972 - acc: 0.6750 - val_loss: 0.4884 - val_acc: 0.7735\n",
      "Epoch 25/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5951 - acc: 0.6778 - val_loss: 0.4939 - val_acc: 0.7726\n",
      "Epoch 26/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5944 - acc: 0.6779 - val_loss: 0.4883 - val_acc: 0.7780\n",
      "Epoch 27/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5937 - acc: 0.6778 - val_loss: 0.4754 - val_acc: 0.7861\n",
      "Epoch 28/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5917 - acc: 0.6799 - val_loss: 0.4789 - val_acc: 0.7817\n",
      "Epoch 29/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5932 - acc: 0.6780 - val_loss: 0.4759 - val_acc: 0.7836\n",
      "Epoch 30/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5940 - acc: 0.6760 - val_loss: 0.4834 - val_acc: 0.7822\n",
      "Epoch 31/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5926 - acc: 0.6792 - val_loss: 0.4769 - val_acc: 0.7886\n",
      "Epoch 32/20000\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.5932 - acc: 0.6765 - val_loss: 0.4784 - val_acc: 0.7840\n",
      "Epoch 33/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5939 - acc: 0.6782 - val_loss: 0.4754 - val_acc: 0.7892\n",
      "Epoch 34/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5909 - acc: 0.6808 - val_loss: 0.4741 - val_acc: 0.7870\n",
      "Epoch 35/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5901 - acc: 0.6819 - val_loss: 0.4689 - val_acc: 0.7913\n",
      "Epoch 36/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5880 - acc: 0.6832 - val_loss: 0.4775 - val_acc: 0.7859\n",
      "Epoch 37/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.5877 - acc: 0.6829 - val_loss: 0.4713 - val_acc: 0.7865\n",
      "Epoch 38/20000\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 0.5876 - acc: 0.6812 - val_loss: 0.4650 - val_acc: 0.7926\n",
      "Epoch 39/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5873 - acc: 0.6829 - val_loss: 0.4731 - val_acc: 0.7864\n",
      "Epoch 40/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5876 - acc: 0.6843 - val_loss: 0.4636 - val_acc: 0.7944\n",
      "Epoch 41/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5852 - acc: 0.6867 - val_loss: 0.4638 - val_acc: 0.7943\n",
      "Epoch 42/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5865 - acc: 0.6828 - val_loss: 0.4633 - val_acc: 0.7930\n",
      "Epoch 43/20000\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 0.5881 - acc: 0.6831 - val_loss: 0.4646 - val_acc: 0.7938\n",
      "Epoch 44/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5871 - acc: 0.6853 - val_loss: 0.4833 - val_acc: 0.7751\n",
      "Epoch 45/20000\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 0.5871 - acc: 0.6843 - val_loss: 0.4739 - val_acc: 0.7879\n",
      "Epoch 46/20000\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 0.5846 - acc: 0.6856 - val_loss: 0.4580 - val_acc: 0.7932\n",
      "Epoch 47/20000\n",
      "12/12 [==============================] - 2s 199ms/step - loss: 0.5840 - acc: 0.6856 - val_loss: 0.4628 - val_acc: 0.7956\n",
      "Epoch 48/20000\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 0.5836 - acc: 0.6853 - val_loss: 0.4653 - val_acc: 0.7909\n",
      "Epoch 49/20000\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 0.5824 - acc: 0.6875 - val_loss: 0.4700 - val_acc: 0.7875\n",
      "Epoch 50/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5823 - acc: 0.6872 - val_loss: 0.4680 - val_acc: 0.7857\n",
      "Epoch 51/20000\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 0.5842 - acc: 0.6854 - val_loss: 0.4668 - val_acc: 0.7883\n",
      "Epoch 52/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5824 - acc: 0.6888 - val_loss: 0.4598 - val_acc: 0.7941\n",
      "Epoch 53/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5826 - acc: 0.6875 - val_loss: 0.4859 - val_acc: 0.7751\n",
      "Epoch 54/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5837 - acc: 0.6878 - val_loss: 0.4694 - val_acc: 0.7880\n",
      "Epoch 55/20000\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 0.5802 - acc: 0.6897 - val_loss: 0.4664 - val_acc: 0.7900\n",
      "Epoch 56/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5786 - acc: 0.6903 - val_loss: 0.4628 - val_acc: 0.7921\n",
      "Epoch 57/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5801 - acc: 0.6901 - val_loss: 0.4659 - val_acc: 0.7869\n",
      "Epoch 58/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5800 - acc: 0.6898 - val_loss: 0.4715 - val_acc: 0.7873\n",
      "Epoch 59/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5797 - acc: 0.6904 - val_loss: 0.4611 - val_acc: 0.7941\n",
      "Epoch 60/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5776 - acc: 0.6920 - val_loss: 0.4577 - val_acc: 0.7963\n",
      "Epoch 61/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5784 - acc: 0.6893 - val_loss: 0.4638 - val_acc: 0.7895\n",
      "Epoch 62/20000\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.5761 - acc: 0.6923 - val_loss: 0.4645 - val_acc: 0.7893\n",
      "Epoch 63/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5771 - acc: 0.6914 - val_loss: 0.4671 - val_acc: 0.7887\n",
      "Epoch 64/20000\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.5751 - acc: 0.6953 - val_loss: 0.4615 - val_acc: 0.7962\n",
      "Epoch 65/20000\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.5759 - acc: 0.6928 - val_loss: 0.4619 - val_acc: 0.7943\n",
      "Epoch 66/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5747 - acc: 0.6953 - val_loss: 0.4632 - val_acc: 0.7916\n",
      "Epoch 67/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5758 - acc: 0.6932 - val_loss: 0.4559 - val_acc: 0.7922\n",
      "Epoch 68/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5753 - acc: 0.6936 - val_loss: 0.4711 - val_acc: 0.7885\n",
      "Epoch 69/20000\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.5755 - acc: 0.6921 - val_loss: 0.4744 - val_acc: 0.7806\n",
      "Epoch 70/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5750 - acc: 0.6933 - val_loss: 0.4645 - val_acc: 0.7920\n",
      "Epoch 71/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5730 - acc: 0.6957 - val_loss: 0.4657 - val_acc: 0.7921\n",
      "Epoch 72/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5732 - acc: 0.6955 - val_loss: 0.4564 - val_acc: 0.7922\n",
      "Epoch 73/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5739 - acc: 0.6953 - val_loss: 0.4614 - val_acc: 0.7954\n",
      "Epoch 74/20000\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.5730 - acc: 0.6971 - val_loss: 0.4660 - val_acc: 0.7874\n",
      "Epoch 75/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5727 - acc: 0.6956 - val_loss: 0.4651 - val_acc: 0.7891\n",
      "Epoch 76/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5721 - acc: 0.6946 - val_loss: 0.4640 - val_acc: 0.7903\n",
      "Epoch 77/20000\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.5714 - acc: 0.6973 - val_loss: 0.4575 - val_acc: 0.7953\n",
      "Epoch 78/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5705 - acc: 0.6979 - val_loss: 0.4679 - val_acc: 0.7906\n",
      "Epoch 79/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5744 - acc: 0.6960 - val_loss: 0.4632 - val_acc: 0.7911\n",
      "Epoch 80/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5709 - acc: 0.6979 - val_loss: 0.4590 - val_acc: 0.7940\n",
      "Epoch 81/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5695 - acc: 0.6986 - val_loss: 0.4699 - val_acc: 0.7853\n",
      "Epoch 82/20000\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.5690 - acc: 0.6983 - val_loss: 0.4586 - val_acc: 0.7933\n",
      "Epoch 83/20000\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 0.5679 - acc: 0.6989 - val_loss: 0.4615 - val_acc: 0.7936\n",
      "Epoch 84/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5670 - acc: 0.7012 - val_loss: 0.4563 - val_acc: 0.7932\n",
      "Epoch 85/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5688 - acc: 0.6968 - val_loss: 0.4578 - val_acc: 0.7920\n",
      "Epoch 86/20000\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5672 - acc: 0.7010 - val_loss: 0.4656 - val_acc: 0.7882\n",
      "Epoch 87/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5669 - acc: 0.6996 - val_loss: 0.4709 - val_acc: 0.7876\n",
      "Epoch 88/20000\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 0.5665 - acc: 0.6979 - val_loss: 0.4660 - val_acc: 0.7886\n",
      "Epoch 89/20000\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.5664 - acc: 0.7007 - val_loss: 0.4569 - val_acc: 0.7928\n",
      "Epoch 90/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5645 - acc: 0.7031 - val_loss: 0.4626 - val_acc: 0.7904\n",
      "Epoch 91/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5666 - acc: 0.6996 - val_loss: 0.4614 - val_acc: 0.7933\n",
      "Epoch 92/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5659 - acc: 0.7020 - val_loss: 0.4671 - val_acc: 0.7883\n",
      "Epoch 93/20000\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 0.5643 - acc: 0.7030 - val_loss: 0.4707 - val_acc: 0.7846\n",
      "Epoch 94/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5648 - acc: 0.7014 - val_loss: 0.4631 - val_acc: 0.7911\n",
      "Epoch 95/20000\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.5639 - acc: 0.7023 - val_loss: 0.4725 - val_acc: 0.7835\n",
      "Epoch 96/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5630 - acc: 0.7034 - val_loss: 0.4629 - val_acc: 0.7930\n",
      "Epoch 97/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5619 - acc: 0.7033 - val_loss: 0.4627 - val_acc: 0.7879\n",
      "Epoch 98/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5642 - acc: 0.7018 - val_loss: 0.4641 - val_acc: 0.7886\n",
      "Epoch 99/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5634 - acc: 0.7033 - val_loss: 0.4621 - val_acc: 0.7917\n",
      "Epoch 100/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5622 - acc: 0.7030 - val_loss: 0.4590 - val_acc: 0.7946\n",
      "Epoch 101/20000\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.5606 - acc: 0.7060 - val_loss: 0.4683 - val_acc: 0.7883\n",
      "Epoch 102/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5640 - acc: 0.7025 - val_loss: 0.4686 - val_acc: 0.7857\n",
      "Epoch 103/20000\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.5626 - acc: 0.7028 - val_loss: 0.4635 - val_acc: 0.7918\n",
      "Epoch 104/20000\n",
      "12/12 [==============================] - 2s 203ms/step - loss: 0.5620 - acc: 0.7039 - val_loss: 0.4581 - val_acc: 0.7942\n",
      "Epoch 105/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5620 - acc: 0.7037 - val_loss: 0.4690 - val_acc: 0.7865\n",
      "Epoch 106/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5622 - acc: 0.7049 - val_loss: 0.4584 - val_acc: 0.7954\n",
      "Epoch 107/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5594 - acc: 0.7057 - val_loss: 0.4647 - val_acc: 0.7883\n",
      "Epoch 108/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5609 - acc: 0.7056 - val_loss: 0.4696 - val_acc: 0.7867\n",
      "Epoch 109/20000\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.5607 - acc: 0.7062 - val_loss: 0.4653 - val_acc: 0.7902\n",
      "Epoch 110/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5615 - acc: 0.7040 - val_loss: 0.4770 - val_acc: 0.7822\n",
      "Epoch 111/20000\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.5582 - acc: 0.7055 - val_loss: 0.4656 - val_acc: 0.7904\n",
      "Epoch 112/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5586 - acc: 0.7073 - val_loss: 0.4718 - val_acc: 0.7836\n",
      "Epoch 113/20000\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 0.5575 - acc: 0.7078 - val_loss: 0.4671 - val_acc: 0.7863\n",
      "Epoch 114/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5568 - acc: 0.7093 - val_loss: 0.4703 - val_acc: 0.7854\n",
      "Epoch 115/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5568 - acc: 0.7080 - val_loss: 0.4702 - val_acc: 0.7864\n",
      "Epoch 116/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5554 - acc: 0.7093 - val_loss: 0.4668 - val_acc: 0.7877\n",
      "Epoch 117/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5567 - acc: 0.7091 - val_loss: 0.4651 - val_acc: 0.7913\n",
      "Epoch 118/20000\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 0.5566 - acc: 0.7093 - val_loss: 0.4818 - val_acc: 0.7838\n",
      "Epoch 119/20000\n",
      "12/12 [==============================] - 2s 194ms/step - loss: 0.5569 - acc: 0.7099 - val_loss: 0.4608 - val_acc: 0.7950\n",
      "Epoch 120/20000\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 0.5583 - acc: 0.7078 - val_loss: 0.4812 - val_acc: 0.7797\n",
      "Epoch 121/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5553 - acc: 0.7095 - val_loss: 0.4756 - val_acc: 0.7836\n",
      "Epoch 122/20000\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.5559 - acc: 0.7086 - val_loss: 0.4739 - val_acc: 0.7829\n",
      "Epoch 123/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5561 - acc: 0.7082 - val_loss: 0.4673 - val_acc: 0.7899\n",
      "Epoch 124/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5540 - acc: 0.7104 - val_loss: 0.4695 - val_acc: 0.7849\n",
      "Epoch 125/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5519 - acc: 0.7097 - val_loss: 0.4836 - val_acc: 0.7781\n",
      "Epoch 126/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5530 - acc: 0.7105 - val_loss: 0.4733 - val_acc: 0.7857\n",
      "Epoch 127/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5512 - acc: 0.7122 - val_loss: 0.4795 - val_acc: 0.7818\n",
      "Epoch 128/20000\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.5545 - acc: 0.7101 - val_loss: 0.4723 - val_acc: 0.7899\n",
      "Epoch 129/20000\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 0.5554 - acc: 0.7085 - val_loss: 0.4691 - val_acc: 0.7911\n",
      "Epoch 130/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5551 - acc: 0.7072 - val_loss: 0.4748 - val_acc: 0.7824\n",
      "Epoch 131/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5562 - acc: 0.7094 - val_loss: 0.4686 - val_acc: 0.7895\n",
      "Epoch 132/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5538 - acc: 0.7118 - val_loss: 0.4728 - val_acc: 0.7864\n",
      "Epoch 133/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5526 - acc: 0.7116 - val_loss: 0.4748 - val_acc: 0.7835\n",
      "Epoch 134/20000\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 0.5524 - acc: 0.7122 - val_loss: 0.4724 - val_acc: 0.7842\n",
      "Epoch 135/20000\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 0.5517 - acc: 0.7121 - val_loss: 0.4719 - val_acc: 0.7849\n",
      "Epoch 136/20000\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.5512 - acc: 0.7120 - val_loss: 0.4827 - val_acc: 0.7815\n",
      "Epoch 137/20000\n",
      "12/12 [==============================] - 2s 203ms/step - loss: 0.5520 - acc: 0.7111 - val_loss: 0.4715 - val_acc: 0.7860\n",
      "Epoch 138/20000\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 0.5507 - acc: 0.7115 - val_loss: 0.4753 - val_acc: 0.7833\n",
      "Epoch 139/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5511 - acc: 0.7130 - val_loss: 0.4766 - val_acc: 0.7851\n",
      "Epoch 140/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5491 - acc: 0.7137 - val_loss: 0.4773 - val_acc: 0.7860\n",
      "Epoch 141/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5508 - acc: 0.7115 - val_loss: 0.4755 - val_acc: 0.7877\n",
      "Epoch 142/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5494 - acc: 0.7134 - val_loss: 0.4726 - val_acc: 0.7856\n",
      "Epoch 143/20000\n",
      "12/12 [==============================] - 2s 174ms/step - loss: 0.5499 - acc: 0.7135 - val_loss: 0.4720 - val_acc: 0.7874\n",
      "Epoch 144/20000\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.5485 - acc: 0.7167 - val_loss: 0.4761 - val_acc: 0.7847\n",
      "Epoch 145/20000\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5489 - acc: 0.7151 - val_loss: 0.4705 - val_acc: 0.7893\n",
      "Epoch 146/20000\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.5492 - acc: 0.7145 - val_loss: 0.4815 - val_acc: 0.7828\n",
      "Epoch 147/20000\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.5476 - acc: 0.7143 - val_loss: 0.4662 - val_acc: 0.7927\n",
      "Epoch 148/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5484 - acc: 0.7137 - val_loss: 0.4716 - val_acc: 0.7867\n",
      "Epoch 149/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.5496 - acc: 0.7129 - val_loss: 0.4793 - val_acc: 0.7838\n",
      "Epoch 150/20000\n",
      "12/12 [==============================] - 2s 195ms/step - loss: 0.5485 - acc: 0.7158 - val_loss: 0.4733 - val_acc: 0.7881\n",
      "Epoch 151/20000\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 0.5469 - acc: 0.7173 - val_loss: 0.4838 - val_acc: 0.7779\n",
      "Epoch 152/20000\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 0.5472 - acc: 0.7168 - val_loss: 0.4833 - val_acc: 0.7850\n",
      "Epoch 153/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5492 - acc: 0.7143 - val_loss: 0.4851 - val_acc: 0.7808\n",
      "Epoch 154/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5485 - acc: 0.7156 - val_loss: 0.4884 - val_acc: 0.7825\n",
      "Epoch 155/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5483 - acc: 0.7163 - val_loss: 0.4822 - val_acc: 0.7811\n",
      "Epoch 156/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5461 - acc: 0.7168 - val_loss: 0.4770 - val_acc: 0.7831\n",
      "Epoch 157/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5466 - acc: 0.7156 - val_loss: 0.4900 - val_acc: 0.7789\n",
      "Epoch 158/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5461 - acc: 0.7194 - val_loss: 0.4751 - val_acc: 0.7861\n",
      "Epoch 159/20000\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 0.5450 - acc: 0.7167 - val_loss: 0.4775 - val_acc: 0.7882\n",
      "Epoch 160/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5444 - acc: 0.7193 - val_loss: 0.4739 - val_acc: 0.7870\n",
      "Epoch 161/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5461 - acc: 0.7169 - val_loss: 0.4798 - val_acc: 0.7828\n",
      "Epoch 162/20000\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.5444 - acc: 0.7171 - val_loss: 0.4848 - val_acc: 0.7805\n",
      "Epoch 163/20000\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 0.5436 - acc: 0.7182 - val_loss: 0.4757 - val_acc: 0.7862\n",
      "Epoch 164/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5444 - acc: 0.7186 - val_loss: 0.4980 - val_acc: 0.7730\n",
      "Epoch 165/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5445 - acc: 0.7189 - val_loss: 0.4824 - val_acc: 0.7819\n",
      "Epoch 166/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5425 - acc: 0.7188 - val_loss: 0.4718 - val_acc: 0.7891\n",
      "Epoch 167/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5413 - acc: 0.7205 - val_loss: 0.4842 - val_acc: 0.7792\n",
      "Epoch 168/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5443 - acc: 0.7182 - val_loss: 0.4785 - val_acc: 0.7870\n",
      "Epoch 169/20000\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.5422 - acc: 0.7194 - val_loss: 0.4905 - val_acc: 0.7794\n",
      "Epoch 170/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5435 - acc: 0.7182 - val_loss: 0.4943 - val_acc: 0.7758\n",
      "Epoch 171/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5424 - acc: 0.7199 - val_loss: 0.4778 - val_acc: 0.7867\n",
      "Epoch 172/20000\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 0.5427 - acc: 0.7185 - val_loss: 0.4821 - val_acc: 0.7855\n",
      "Epoch 173/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5425 - acc: 0.7195 - val_loss: 0.4801 - val_acc: 0.7825\n",
      "Epoch 174/20000\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5412 - acc: 0.7203 - val_loss: 0.4935 - val_acc: 0.7750\n",
      "Epoch 175/20000\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5411 - acc: 0.7223 - val_loss: 0.4885 - val_acc: 0.7786\n",
      "Epoch 176/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5416 - acc: 0.7197 - val_loss: 0.4819 - val_acc: 0.7815\n",
      "Epoch 177/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5415 - acc: 0.7201 - val_loss: 0.4873 - val_acc: 0.7795\n",
      "Epoch 178/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5419 - acc: 0.7198 - val_loss: 0.4804 - val_acc: 0.7835\n",
      "Epoch 179/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5395 - acc: 0.7211 - val_loss: 0.4873 - val_acc: 0.7792\n",
      "Epoch 180/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5431 - acc: 0.7190 - val_loss: 0.4906 - val_acc: 0.7784\n",
      "Epoch 181/20000\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.5414 - acc: 0.7206 - val_loss: 0.4871 - val_acc: 0.7788\n",
      "Epoch 182/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5403 - acc: 0.7212 - val_loss: 0.4834 - val_acc: 0.7814\n",
      "Epoch 183/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5394 - acc: 0.7231 - val_loss: 0.4792 - val_acc: 0.7827\n",
      "Epoch 184/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5417 - acc: 0.7189 - val_loss: 0.4791 - val_acc: 0.7869\n",
      "Epoch 185/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5410 - acc: 0.7212 - val_loss: 0.4872 - val_acc: 0.7791\n",
      "Epoch 186/20000\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 0.5391 - acc: 0.7219 - val_loss: 0.4953 - val_acc: 0.7758\n",
      "Epoch 187/20000\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.5406 - acc: 0.7201 - val_loss: 0.4934 - val_acc: 0.7797\n",
      "Epoch 188/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5380 - acc: 0.7220 - val_loss: 0.4933 - val_acc: 0.7757\n",
      "Epoch 189/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5375 - acc: 0.7221 - val_loss: 0.4867 - val_acc: 0.7803\n",
      "Epoch 190/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.5361 - acc: 0.7224 - val_loss: 0.5015 - val_acc: 0.7761\n",
      "Epoch 191/20000\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 0.5364 - acc: 0.7246 - val_loss: 0.4852 - val_acc: 0.7842\n",
      "Epoch 192/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5371 - acc: 0.7231 - val_loss: 0.4780 - val_acc: 0.7854\n",
      "Epoch 193/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5361 - acc: 0.7249 - val_loss: 0.4884 - val_acc: 0.7786\n",
      "Epoch 194/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5382 - acc: 0.7237 - val_loss: 0.4933 - val_acc: 0.7780\n",
      "Epoch 195/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5391 - acc: 0.7224 - val_loss: 0.4867 - val_acc: 0.7805\n",
      "Epoch 196/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5364 - acc: 0.7243 - val_loss: 0.4895 - val_acc: 0.7814\n",
      "Epoch 197/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5384 - acc: 0.7220 - val_loss: 0.4912 - val_acc: 0.7798\n",
      "Epoch 198/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.5372 - acc: 0.7231 - val_loss: 0.4930 - val_acc: 0.7762\n",
      "Epoch 199/20000\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 0.5371 - acc: 0.7246 - val_loss: 0.4889 - val_acc: 0.7813\n",
      "Epoch 200/20000\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.5389 - acc: 0.7228 - val_loss: 0.4846 - val_acc: 0.7804\n",
      "Epoch 201/20000\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.5378 - acc: 0.7224 - val_loss: 0.4903 - val_acc: 0.7802\n",
      "Epoch 202/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5353 - acc: 0.7241 - val_loss: 0.4950 - val_acc: 0.7765\n",
      "Epoch 203/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5351 - acc: 0.7254 - val_loss: 0.4857 - val_acc: 0.7822\n",
      "Epoch 204/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5355 - acc: 0.7274 - val_loss: 0.4963 - val_acc: 0.7752\n",
      "Epoch 205/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5359 - acc: 0.7234 - val_loss: 0.4837 - val_acc: 0.7834\n",
      "Epoch 206/20000\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.5381 - acc: 0.7226 - val_loss: 0.4946 - val_acc: 0.7782\n",
      "Epoch 207/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5370 - acc: 0.7238 - val_loss: 0.4999 - val_acc: 0.7779\n",
      "Epoch 208/20000\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5354 - acc: 0.7259 - val_loss: 0.4886 - val_acc: 0.7787\n",
      "Epoch 209/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.5359 - acc: 0.7251 - val_loss: 0.4939 - val_acc: 0.7824\n",
      "Epoch 210/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5327 - acc: 0.7277 - val_loss: 0.4927 - val_acc: 0.7810\n",
      "Epoch 211/20000\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.5334 - acc: 0.7277 - val_loss: 0.4939 - val_acc: 0.7797\n",
      "Epoch 212/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5341 - acc: 0.7240 - val_loss: 0.4923 - val_acc: 0.7809\n",
      "Epoch 213/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5333 - acc: 0.7269 - val_loss: 0.4855 - val_acc: 0.7856\n",
      "Epoch 214/20000\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.5349 - acc: 0.7252 - val_loss: 0.4909 - val_acc: 0.7785\n",
      "Epoch 215/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5364 - acc: 0.7252 - val_loss: 0.5083 - val_acc: 0.7758\n",
      "Epoch 216/20000\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.5357 - acc: 0.7240 - val_loss: 0.5013 - val_acc: 0.7732\n",
      "Epoch 217/20000\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.5331 - acc: 0.7254 - val_loss: 0.4840 - val_acc: 0.7826\n",
      "Epoch 218/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5344 - acc: 0.7251 - val_loss: 0.4924 - val_acc: 0.7814\n",
      "Epoch 219/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5357 - acc: 0.7238 - val_loss: 0.4940 - val_acc: 0.7772\n",
      "Epoch 220/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5341 - acc: 0.7256 - val_loss: 0.4945 - val_acc: 0.7829\n",
      "Epoch 221/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5311 - acc: 0.7269 - val_loss: 0.4851 - val_acc: 0.7819\n",
      "Epoch 222/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5329 - acc: 0.7270 - val_loss: 0.4886 - val_acc: 0.7831\n",
      "Epoch 223/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5320 - acc: 0.7261 - val_loss: 0.5077 - val_acc: 0.7715\n",
      "Epoch 224/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5308 - acc: 0.7284 - val_loss: 0.4975 - val_acc: 0.7784\n",
      "Epoch 225/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5328 - acc: 0.7257 - val_loss: 0.5020 - val_acc: 0.7765\n",
      "Epoch 226/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5337 - acc: 0.7273 - val_loss: 0.5017 - val_acc: 0.7675\n",
      "Epoch 227/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5329 - acc: 0.7262 - val_loss: 0.4938 - val_acc: 0.7784\n",
      "Epoch 228/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5335 - acc: 0.7263 - val_loss: 0.5002 - val_acc: 0.7730\n",
      "Epoch 229/20000\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 0.5329 - acc: 0.7288 - val_loss: 0.4996 - val_acc: 0.7767\n",
      "Epoch 230/20000\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.5313 - acc: 0.7278 - val_loss: 0.5016 - val_acc: 0.7771\n",
      "Epoch 231/20000\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.5350 - acc: 0.7270 - val_loss: 0.5138 - val_acc: 0.7722\n",
      "Epoch 232/20000\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.5318 - acc: 0.7278 - val_loss: 0.4942 - val_acc: 0.7775\n",
      "Epoch 233/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5356 - acc: 0.7258 - val_loss: 0.5077 - val_acc: 0.7739\n",
      "Epoch 234/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5337 - acc: 0.7249 - val_loss: 0.5008 - val_acc: 0.7742\n",
      "Epoch 235/20000\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.5311 - acc: 0.7284 - val_loss: 0.5114 - val_acc: 0.7682\n",
      "Epoch 236/20000\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.5310 - acc: 0.7277 - val_loss: 0.4955 - val_acc: 0.7798\n",
      "Epoch 237/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5302 - acc: 0.7289 - val_loss: 0.5024 - val_acc: 0.7772\n",
      "Epoch 238/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5309 - acc: 0.7282 - val_loss: 0.4977 - val_acc: 0.7768\n",
      "Epoch 239/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5291 - acc: 0.7278 - val_loss: 0.5019 - val_acc: 0.7777\n",
      "Epoch 240/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5313 - acc: 0.7266 - val_loss: 0.5027 - val_acc: 0.7761\n",
      "Epoch 241/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5284 - acc: 0.7298 - val_loss: 0.5128 - val_acc: 0.7698\n",
      "Epoch 242/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5300 - acc: 0.7291 - val_loss: 0.5122 - val_acc: 0.7707\n",
      "Epoch 243/20000\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.5310 - acc: 0.7283 - val_loss: 0.5167 - val_acc: 0.7679\n",
      "Epoch 244/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5300 - acc: 0.7273 - val_loss: 0.5152 - val_acc: 0.7694\n",
      "Epoch 245/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5304 - acc: 0.7281 - val_loss: 0.5073 - val_acc: 0.7732\n",
      "Epoch 246/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5294 - acc: 0.7272 - val_loss: 0.5027 - val_acc: 0.7795\n",
      "Epoch 247/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5279 - acc: 0.7300 - val_loss: 0.5042 - val_acc: 0.7765\n",
      "Epoch 248/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5267 - acc: 0.7317 - val_loss: 0.5011 - val_acc: 0.7765\n",
      "Epoch 249/20000\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.5279 - acc: 0.7295 - val_loss: 0.5047 - val_acc: 0.7787\n",
      "Epoch 250/20000\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.5297 - acc: 0.7290 - val_loss: 0.5149 - val_acc: 0.7719\n",
      "Epoch 251/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5285 - acc: 0.7286 - val_loss: 0.5100 - val_acc: 0.7768\n",
      "Epoch 252/20000\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 0.5276 - acc: 0.7303 - val_loss: 0.4999 - val_acc: 0.7788\n",
      "Epoch 253/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5263 - acc: 0.7308 - val_loss: 0.5123 - val_acc: 0.7737\n",
      "Epoch 254/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5279 - acc: 0.7302 - val_loss: 0.5203 - val_acc: 0.7663\n",
      "Epoch 255/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5248 - acc: 0.7323 - val_loss: 0.5074 - val_acc: 0.7767\n",
      "Epoch 256/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5256 - acc: 0.7310 - val_loss: 0.5136 - val_acc: 0.7706\n",
      "Epoch 257/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5271 - acc: 0.7290 - val_loss: 0.5170 - val_acc: 0.7716\n",
      "Epoch 258/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5282 - acc: 0.7305 - val_loss: 0.5041 - val_acc: 0.7766\n",
      "Epoch 259/20000\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 0.5275 - acc: 0.7301 - val_loss: 0.5035 - val_acc: 0.7793\n",
      "Epoch 260/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5268 - acc: 0.7321 - val_loss: 0.5001 - val_acc: 0.7771\n",
      "Epoch 261/20000\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.5247 - acc: 0.7340 - val_loss: 0.5139 - val_acc: 0.7714\n",
      "Epoch 262/20000\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.5263 - acc: 0.7313 - val_loss: 0.5168 - val_acc: 0.7725\n",
      "Epoch 263/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5242 - acc: 0.7327 - val_loss: 0.5151 - val_acc: 0.7736\n",
      "Epoch 264/20000\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 0.5253 - acc: 0.7315 - val_loss: 0.5080 - val_acc: 0.7769\n",
      "Epoch 265/20000\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.5263 - acc: 0.7311 - val_loss: 0.5167 - val_acc: 0.7707\n",
      "Epoch 266/20000\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5265 - acc: 0.7311 - val_loss: 0.5083 - val_acc: 0.7741\n",
      "Epoch 267/20000\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 0.5266 - acc: 0.7293 - val_loss: 0.5076 - val_acc: 0.7782\n",
      "Epoch 268/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5272 - acc: 0.7307 - val_loss: 0.5115 - val_acc: 0.7728\n",
      "Epoch 269/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5271 - acc: 0.7305 - val_loss: 0.5229 - val_acc: 0.7673\n",
      "Epoch 270/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5267 - acc: 0.7307 - val_loss: 0.5217 - val_acc: 0.7651\n",
      "Epoch 271/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5277 - acc: 0.7305 - val_loss: 0.5158 - val_acc: 0.7726\n",
      "Epoch 272/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5278 - acc: 0.7291 - val_loss: 0.5110 - val_acc: 0.7732\n",
      "Epoch 273/20000\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.5246 - acc: 0.7311 - val_loss: 0.5111 - val_acc: 0.7754\n",
      "Epoch 274/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5242 - acc: 0.7334 - val_loss: 0.5097 - val_acc: 0.7722\n",
      "Epoch 275/20000\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.5244 - acc: 0.7332 - val_loss: 0.5316 - val_acc: 0.7659\n",
      "Epoch 276/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5235 - acc: 0.7319 - val_loss: 0.5129 - val_acc: 0.7736\n",
      "Epoch 277/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5236 - acc: 0.7320 - val_loss: 0.5128 - val_acc: 0.7764\n",
      "Epoch 278/20000\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 0.5234 - acc: 0.7339 - val_loss: 0.5208 - val_acc: 0.7709\n",
      "Epoch 279/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5239 - acc: 0.7332 - val_loss: 0.5260 - val_acc: 0.7690\n",
      "Epoch 280/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5239 - acc: 0.7333 - val_loss: 0.5159 - val_acc: 0.7748\n",
      "Epoch 281/20000\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.5226 - acc: 0.7338 - val_loss: 0.5152 - val_acc: 0.7729\n",
      "Epoch 282/20000\n",
      "12/12 [==============================] - 2s 182ms/step - loss: 0.5247 - acc: 0.7322 - val_loss: 0.5128 - val_acc: 0.7747\n",
      "Epoch 283/20000\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.5235 - acc: 0.7331 - val_loss: 0.5123 - val_acc: 0.7773\n",
      "Epoch 284/20000\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.5235 - acc: 0.7328 - val_loss: 0.5150 - val_acc: 0.7724\n",
      "Epoch 285/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5232 - acc: 0.7347 - val_loss: 0.5079 - val_acc: 0.7762\n",
      "Epoch 286/20000\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.5236 - acc: 0.7331 - val_loss: 0.5204 - val_acc: 0.7694\n",
      "Epoch 287/20000\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 0.5262 - acc: 0.7319 - val_loss: 0.5254 - val_acc: 0.7693\n",
      "Epoch 288/20000\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.5263 - acc: 0.7320 - val_loss: 0.5235 - val_acc: 0.7664\n",
      "Epoch 289/20000\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 0.5242 - acc: 0.7335 - val_loss: 0.5463 - val_acc: 0.7602\n",
      "Epoch 290/20000\n",
      "12/12 [==============================] - 2s 173ms/step - loss: 0.5275 - acc: 0.7299 - val_loss: 0.5190 - val_acc: 0.7709\n",
      "Epoch 291/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5272 - acc: 0.7323 - val_loss: 0.5117 - val_acc: 0.7751\n",
      "Epoch 292/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5224 - acc: 0.7343 - val_loss: 0.5304 - val_acc: 0.7672\n",
      "Epoch 293/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5243 - acc: 0.7334 - val_loss: 0.5068 - val_acc: 0.7773\n",
      "Epoch 294/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5227 - acc: 0.7331 - val_loss: 0.5270 - val_acc: 0.7661\n",
      "Epoch 295/20000\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.5239 - acc: 0.7350 - val_loss: 0.5154 - val_acc: 0.7737\n",
      "Epoch 296/20000\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.5231 - acc: 0.7346 - val_loss: 0.5190 - val_acc: 0.7723\n",
      "Epoch 297/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5212 - acc: 0.7351 - val_loss: 0.5160 - val_acc: 0.7729\n",
      "Epoch 298/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5240 - acc: 0.7345 - val_loss: 0.5153 - val_acc: 0.7722\n",
      "Epoch 299/20000\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 0.5216 - acc: 0.7341 - val_loss: 0.5265 - val_acc: 0.7682\n",
      "Epoch 300/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5237 - acc: 0.7333 - val_loss: 0.5197 - val_acc: 0.7722\n",
      "Epoch 301/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5226 - acc: 0.7342 - val_loss: 0.5380 - val_acc: 0.7650\n",
      "Epoch 302/20000\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.5229 - acc: 0.7340 - val_loss: 0.5179 - val_acc: 0.7743\n",
      "Epoch 303/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5247 - acc: 0.7298 - val_loss: 0.5146 - val_acc: 0.7734\n",
      "Epoch 304/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5216 - acc: 0.7351 - val_loss: 0.5206 - val_acc: 0.7682\n",
      "Epoch 305/20000\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 0.5211 - acc: 0.7348 - val_loss: 0.5280 - val_acc: 0.7683\n",
      "Epoch 306/20000\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 0.5200 - acc: 0.7336 - val_loss: 0.5200 - val_acc: 0.7710\n",
      "Epoch 307/20000\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 0.5226 - acc: 0.7346 - val_loss: 0.5267 - val_acc: 0.7675\n",
      "Epoch 308/20000\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 0.5223 - acc: 0.7336 - val_loss: 0.5187 - val_acc: 0.7724\n",
      "Epoch 309/20000\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.5227 - acc: 0.7328 - val_loss: 0.5339 - val_acc: 0.7682\n",
      "Epoch 310/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5208 - acc: 0.7348 - val_loss: 0.5111 - val_acc: 0.7745\n",
      "Epoch 311/20000\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 0.5202 - acc: 0.7358 - val_loss: 0.5150 - val_acc: 0.7707\n",
      "Epoch 312/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5209 - acc: 0.7350 - val_loss: 0.5223 - val_acc: 0.7700\n",
      "Epoch 313/20000\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.5191 - acc: 0.7355 - val_loss: 0.5210 - val_acc: 0.7706\n",
      "Epoch 314/20000\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 0.5207 - acc: 0.7349 - val_loss: 0.5250 - val_acc: 0.7696\n",
      "Epoch 315/20000\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.5197 - acc: 0.7368 - val_loss: 0.5245 - val_acc: 0.7711\n",
      "Epoch 316/20000\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 0.5223 - acc: 0.7348 - val_loss: 0.5327 - val_acc: 0.7689\n",
      "Epoch 317/20000\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 0.5205 - acc: 0.7354 - val_loss: 0.5245 - val_acc: 0.7697\n",
      "Epoch 318/20000\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.5213 - acc: 0.7346 - val_loss: 0.5282 - val_acc: 0.7680\n",
      "Epoch 319/20000\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.5191 - acc: 0.7357 - val_loss: 0.5161 - val_acc: 0.7755\n",
      "Epoch 320/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5214 - acc: 0.7357 - val_loss: 0.5191 - val_acc: 0.7735\n",
      "Epoch 321/20000\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.5196 - acc: 0.7342 - val_loss: 0.5543 - val_acc: 0.7579\n",
      "Epoch 322/20000\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.5219 - acc: 0.7347 - val_loss: 0.5306 - val_acc: 0.7655\n",
      "Epoch 323/20000\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.5233 - acc: 0.7336 - val_loss: 0.5402 - val_acc: 0.7647\n",
      "Epoch 324/20000\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.5177 - acc: 0.7365 - val_loss: 0.5321 - val_acc: 0.7676\n",
      "Epoch 325/20000\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.5230 - acc: 0.7342 - val_loss: 0.5284 - val_acc: 0.7683\n",
      "Epoch 326/20000\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.5195 - acc: 0.7360 - val_loss: 0.5279 - val_acc: 0.7645\n",
      "Epoch 327/20000\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.5195 - acc: 0.7366 - val_loss: 0.5298 - val_acc: 0.7706\n",
      "Epoch 328/20000\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.5223 - acc: 0.7341 - val_loss: 0.5262 - val_acc: 0.7712\n",
      "Epoch 329/20000\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.5201 - acc: 0.7369 - val_loss: 0.5215 - val_acc: 0.7718\n",
      "Epoch 330/20000\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.5179 - acc: 0.7361 - val_loss: 0.5247 - val_acc: 0.7703\n",
      "Epoch 331/20000\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.5203 - acc: 0.7351 - val_loss: 0.5249 - val_acc: 0.7688\n",
      "Epoch 332/20000\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 0.5179 - acc: 0.7393 - val_loss: 0.5245 - val_acc: 0.7707\n",
      "Epoch 333/20000\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.5191 - acc: 0.7371 - val_loss: 0.5305 - val_acc: 0.7697\n",
      "Epoch 334/20000\n",
      "12/12 [==============================] - 2s 200ms/step - loss: 0.5181 - acc: 0.7367 - val_loss: 0.5374 - val_acc: 0.7654\n",
      "Epoch 335/20000\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5197 - acc: 0.7396 - val_loss: 0.5254 - val_acc: 0.7723\n",
      "Epoch 336/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5182 - acc: 0.7380 - val_loss: 0.5280 - val_acc: 0.7719\n",
      "Epoch 337/20000\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.5198 - acc: 0.7357 - val_loss: 0.5497 - val_acc: 0.7629\n",
      "Epoch 338/20000\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.5186 - acc: 0.7355 - val_loss: 0.5266 - val_acc: 0.7723\n",
      "Epoch 339/20000\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.5182 - acc: 0.7367 - val_loss: 0.5322 - val_acc: 0.7691\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.3\n",
    "for hidden_layer in range(700, 1201, 100):\n",
    "    for learning_rate in range(15,46,10):\n",
    "        learning_rate = learning_rate / 1000\n",
    "        dataframe = pd.read_csv('../data/matches.csv')[7389:76425]\n",
    "        validation = pd.read_csv('../data/matches.csv')[76425:]\n",
    "        data_model, features_dict, labels = get_model(dataframe, hidden_layer, learning_rate, dropout)\n",
    "        _, val_features_dict, val_labels = get_model(validation, hidden_layer, learning_rate, dropout)\n",
    "\n",
    "        for trial in range(5):\n",
    "            data_model.fit(x=features_dict, y=labels, epochs=20000, batch_size=6000, \n",
    "                        callbacks=[tf.keras.callbacks.EarlyStopping('loss', patience=15)],\n",
    "                        validation_data=(val_features_dict, val_labels),\n",
    "                    )\n",
    "            # data_model.save(f'test{trial}')\n",
    "            data_model.save(f'hidden{hidden_layer}lr{learning_rate}dropout{dropout}trial{trial}')\n",
    "\n",
    "\n",
    "\n",
    "# data_model, features_dict, labels = get_model(dataframe, 0,0,0)\n",
    "# _, val_features_dict, val_labels = get_model(validation, 0,0,0)\n",
    "# tuner = kt.BayesianOptimization(data_model, objective='loss', directory='training_weights', max_trials=80)\n",
    "# tuner.search(x=features_dict, y=labels, epochs=20000, \n",
    "#              validation_data=(val_features_dict, val_labels),\n",
    "#              callbacks=[tf.keras.callbacks.EarlyStopping('loss', patience=15)]\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at hidden800lr0.021dropout0.45trial0.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reloaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mhidden800lr0.021dropout0.45trial0.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m results \u001b[39m=\u001b[39m reloaded\u001b[39m.\u001b[39mevaluate(val_features_dict, val_labels)\n\u001b[0;32m      3\u001b[0m val_predictions \u001b[39m=\u001b[39m reloaded\u001b[39m.\u001b[39mpredict(val_features_dict)\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\andyw\\OneDrive\\Desktop\\Projects\\tennis-ml\\env\\lib\\site-packages\\keras\\saving\\legacy\\save.py:227\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    226\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    232\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    233\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    234\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at hidden800lr0.021dropout0.45trial0.csv"
     ]
    }
   ],
   "source": [
    "reloaded = tf.keras.models.load_model('hidden800lr0.021dropout0.45trial0.csv')\n",
    "results = reloaded.evaluate(val_features_dict, val_labels)\n",
    "val_predictions = reloaded.predict(val_features_dict)\n",
    "val_labels_list = val_labels.tolist()\n",
    "\n",
    "predictions = reloaded.predict(features_dict)\n",
    "labels_list = labels.tolist()\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = calibration_curve(val_labels_list, val_predictions, n_bins = 100)\n",
    "plt.plot(y, x, 'b')\n",
    "plt.plot([0, 1], [0, 1])\n",
    "\n",
    "x, y = calibration_curve(labels_list, predictions, n_bins = 100)\n",
    "plt.plot(y, x, 'r')\n",
    "plt.plot([0, 1], [0, 1])\n",
    "\n",
    "\n",
    "#_____________________________________________________________\n",
    "# validation = pd.read_csv('../data/matches.csv')[85000:]\n",
    "# _, val_features_dict, val_labels = get_model(validation)\n",
    "\n",
    "\n",
    "# data_model.load_weights('asdf/metrics')\n",
    "# results = data_model.evaluate(val_features_dict, val_labels)\n",
    "# predictions = data_model.predict(val_features_dict)\n",
    "# labels_list = val_labels.tolist()\n",
    "# print(len(val_features_dict), len(labels_list))\n",
    "# print(val_features_dict)\n",
    "\n",
    "# for i in range(0, len(predictions)):\n",
    "#     print('Prediction:', predictions[i], 'Result:', labels_list[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c387c56ae450897d1d6677bb1bb04b8f7b3f7f9924967827e96c8d61cb0c0e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
